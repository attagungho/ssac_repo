{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. 데이터 수집하기\n",
    "\n",
    "데이터는 아래 링크에 있는 뉴스 기사 데이터(newssummarymore.csv)를 사용하세요.\n",
    "sunnysai12345/News_Summary\n",
    "\n",
    "아래의 코드로 데이터를 다운로드 할 수 있어요.\n",
    "```\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "data.sample(10)\n",
    "```\n",
    "\n",
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. 추출적 요약을 하는 경우에는 오직 text열만을 사용하세요.\n",
    "\n",
    "Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해보세요.\n",
    "\n",
    "Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.\n",
    "\n",
    "Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해보세요.\n",
    "Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가문항\t상세기준\n",
    "\n",
    "1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.\n",
    "\t분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "\n",
    "2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.\n",
    "\t모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.\n",
    "\n",
    "3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.\n",
    "\t두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98064</th>\n",
       "      <td>IPL money isn't real until it goes into my acc...</td>\n",
       "      <td>English fast bowler Tymal Mills, who was bough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Govt to confer 4 Padma Vibhushan, 14 Padma Bhu...</td>\n",
       "      <td>The Government of India on Friday announced fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49006</th>\n",
       "      <td>Why were Man Utd players killed in crash calle...</td>\n",
       "      <td>'Busby Babes' is the name given to Manchester ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80579</th>\n",
       "      <td>Would ask Putin whom he supported for presiden...</td>\n",
       "      <td>US President Donald Trump has said he would as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77313</th>\n",
       "      <td>Titan's profit rises 96.8% to Ã¢ÂÂ¹238 crore ...</td>\n",
       "      <td>Jewellery and watch maker Titan Company saw it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87891</th>\n",
       "      <td>Swara slams Paresh's 'tie Arundhati to Army je...</td>\n",
       "      <td>Actress Swara Bhasker slammed actor and BJP MP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45029</th>\n",
       "      <td>Should men be allowed to ask kids for sexual p...</td>\n",
       "      <td>In a survey, Facebook asked users if men shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84284</th>\n",
       "      <td>Technology is certainly replacing jobs: Facebo...</td>\n",
       "      <td>Social media platform Facebook's Chief Operati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Manish Pandey replaces Vinay Kumar as Karnatak...</td>\n",
       "      <td>The Karnataka State Cricket Association announ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91523</th>\n",
       "      <td>World's oldest fungus discovered in South Africa</td>\n",
       "      <td>Fungus-like organisms have been found fossilis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "98064  IPL money isn't real until it goes into my acc...   \n",
       "721    Govt to confer 4 Padma Vibhushan, 14 Padma Bhu...   \n",
       "49006  Why were Man Utd players killed in crash calle...   \n",
       "80579  Would ask Putin whom he supported for presiden...   \n",
       "77313  Titan's profit rises 96.8% to Ã¢ÂÂ¹238 crore ...   \n",
       "87891  Swara slams Paresh's 'tie Arundhati to Army je...   \n",
       "45029  Should men be allowed to ask kids for sexual p...   \n",
       "84284  Technology is certainly replacing jobs: Facebo...   \n",
       "4081   Manish Pandey replaces Vinay Kumar as Karnatak...   \n",
       "91523   World's oldest fungus discovered in South Africa   \n",
       "\n",
       "                                                    text  \n",
       "98064  English fast bowler Tymal Mills, who was bough...  \n",
       "721    The Government of India on Friday announced fo...  \n",
       "49006  'Busby Babes' is the name given to Manchester ...  \n",
       "80579  US President Donald Trump has said he would as...  \n",
       "77313  Jewellery and watch maker Titan Company saw it...  \n",
       "87891  Actress Swara Bhasker slammed actor and BJP MP...  \n",
       "45029  In a survey, Facebook asked users if men shoul...  \n",
       "84284  Social media platform Facebook's Chief Operati...  \n",
       "4081   The Karnataka State Cricket Association announ...  \n",
       "91523  Fungus-like organisms have been found fossilis...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['headlines', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15075    A 44-year-old woman arrested in West Bengal fo...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great fact ordered twice third ordered mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = \"Everything I bought was great, 'cause in fact I ordered twice and the third ordered was<br /> for my mother and father.\"\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'in' in eng_stopwords:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time: 525.1492238044739\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "print(f'elasped time: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "temp_list = copy.deepcopy(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list.extend(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp_list).duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 전처리 전 후 동일한 항목이 39개 뿐인 것을 보면 전처리가 잘 된 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indian golfer shiv kapur third asian tour title lifting royal cup thailand sunday year old golfer one asian tour win till april three asian tour titles last eight months kapur first asian tour debut season december']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(clean_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 54252, sentence: indian golfer shiv kapur third asian tour title lifting royal cup thailand sunday year old golfer one asian tour win till april three asian tour titles last eight months kapur first asian tour debut season december\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(clean_text):\n",
    "    if 'indian golfer shiv kapur' in s:\n",
    "        print(f'index: {i}, sentence: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indian golfer Shiv Kapur won his third Asian Tour title of 2017 by lifting the Royal Cup in Thailand on Sunday. The 35-year-old golfer, who had just one Asian Tour win till April 2017, has now won three Asian Tour titles in the last eight months. Kapur first won on Asian Tour in his debut season in December 2005.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.iloc[54252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indian golfer Shiv Kapur wins third Asian Tour title of 2017'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.headlines.iloc[54252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'won' in stopwords.words('english'):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 축약어 변형 후 won은 win의 과거나 과거분사형 밖에 없으므로 해당 단어는 stopwords에서 제거해 주는 것이 좋겠다. stopwords에 무엇이 들어있는지 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't, "
     ]
    }
   ],
   "source": [
    "for t in eng_stopwords:\n",
    "    print(t, end= ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 축약어를 풀어낸 후에 stopwords를 제거하는 작업을 할 것이므로 stopwords에서 won만 제거해 주면 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords.remove('won')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if 'won' in eng_stopwords:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in eng_stopwords if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time: 30.233577251434326\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "print(f'elasped time: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian golfer shiv kapur won third asian tour title lifting royal cup thailand sunday year old golfer one asian tour win till april won three asian tour titles last eight months kapur first won asian tour debut season december\n"
     ]
    }
   ],
   "source": [
    "print(clean_text[54252])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 전처리가 잘 된것 같다. stpowords.words('englis')를 직접 반복분에 넣어서 활용하는 것 보다 별도 object로 받아와서 실행하니 전처리도 더 빨리 진행 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time: 17.48799443244934\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clean_headline = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headline.append(preprocess_sentence(s, False))\n",
    "print(f'elasped time: {time.time()-start}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boko haram kidnapped schoolgirls by accident reports']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(clean_headline, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 74841, sentence: boko haram kidnapped schoolgirls by accident reports\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(clean_headline):\n",
    "    if 'boko haram kidnapped' in s:\n",
    "        print(f'index: {i}, sentence: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boko Haram kidnapped 200 schoolgirls by accident: Reports'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.headlines.iloc[74841]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 숫자는 없어도 요약 뜻을 보는데에는 큰 문제 없을 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headline\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "\n",
       "                                                text  \n",
       "0  saurav kant alumnus upgrad iiit pg program mac...  \n",
       "1  kunal shah credit card bill payment platform c...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/news_summarization/data/preprocessed_news.csv'\n",
    "data.to_csv(csv_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 나중을 위해서 csv는 저장을 해두도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/news_summarization/data/preprocessed_news.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "data = data.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.12512200081334\n",
      "텍스트 길이 표준편차 : 3.8047282332638988\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 16\n",
      "헤드라인의 평균 길이 : 9.299532330215534\n",
      "헤드라인 길이 표준편차 : 1.3900944321771693\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print(f'텍스트 길이 표준편차 : {np.std(text_len)}')\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "print(f'헤드라인 길이 표준편차 : {np.std(summary_len)}')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headline')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('healine')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 52, text: text, headline: headlines\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(text_len):\n",
    "    if s == 1:\n",
    "        print(f'index: {i}, text: {data.text.iloc[i]}, headline: {data.headlines.iloc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 18, 19]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.Series(text_len).unique())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.Series(summary_len).unique())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 52,headline: headlines\n",
      "index: 729,headline: angola decriminalises homosexuality\n",
      "index: 26211,headline: what is friggatriskaidekaphobia\n",
      "index: 42036,headline: twitter bans cryptocurrency advertisements\n",
      "index: 42294,headline: intelligence bureau transfers officers\n",
      "index: 46615,headline: transferred employees not pnb\n",
      "index: 48287,headline: mirinda launches releasethepressure campaign\n",
      "index: 49718,headline: cabinet approves union budget\n",
      "index: 52838,headline: lendingkart finance raises million\n",
      "index: 55175,headline: infosys completes crore buyback\n",
      "index: 57420,headline: marijuana wreath being sold\n",
      "index: 58671,headline: currency note completes years\n",
      "index: 59665,headline: why is thanksgiving celebrated\n",
      "index: 78594,headline: karnataka education officers transferred\n",
      "index: 92550,headline: htc teases squeezable smartphone\n",
      "index: 93866,headline: pulitzer prize winners announced\n",
      "index: 96647,headline: in pictures earth hour\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(summary_len):\n",
    "    if s < 5:\n",
    "        print(f'index: {i},headline: {data.headlines.iloc[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 짧은 쪽에서는 길이가 1인 데이터만 잘라내면 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 38\n",
    "headline_max_len = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 38 이하인 샘플의 비율: 0.814304595363969\n",
      "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.9449877999186661\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headline_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 중 길이 기준 이하 샘플 비율: 0.768239121594144\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(data)):\n",
    "    if len(data.text.iloc[i].split()) <= text_max_len and len(data.headlines.iloc[i].split()) <= headline_max_len:\n",
    "        cnt = cnt+1\n",
    "print(f'전체 데이터 중 길이 기준 이하 샘플 비율: {(cnt-1) / len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75565"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75540.48"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) * 0.768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 75564\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len and len(x.split()) != 1)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headline_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "      <td>weeks ex cbi director alok verma told departme...</td>\n",
       "      <td>sostoken govt directs alok verma to join work ...</td>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>called pm modi sir times to satisfy his ego an...</td>\n",
       "      <td>andhra pradesh cm chandrababu naidu said met u...</td>\n",
       "      <td>sostoken called pm modi sir times to satisfy h...</td>\n",
       "      <td>called pm modi sir times to satisfy his ego an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "7  govt directs alok verma to join work day befor...   \n",
       "8  called pm modi sir times to satisfy his ego an...   \n",
       "\n",
       "                                                text  \\\n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "7  weeks ex cbi director alok verma told departme...   \n",
       "8  andhra pradesh cm chandrababu naidu said met u...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "7  sostoken govt directs alok verma to join work ...   \n",
       "8  sostoken called pm modi sir times to satisfy h...   \n",
       "\n",
       "                                      decoder_target  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  \n",
       "7  govt directs alok verma to join work day befor...  \n",
       "8  called pm modi sir times to satisfy his ego an...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75564,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48011 61376 22969 ... 60525  7043 39609]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 15112\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 60452\n",
      "훈련 레이블의 개수 : 60452\n",
      "테스트 데이터의 개수 : 15112\n",
      "테스트 레이블의 개수 : 15112\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 60250\n",
      "등장 빈도가 7번 이하인 희귀 단어의 수: 42509\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 17741\n",
      "단어 집합에서 희귀 단어의 비율: 70.55435684647303\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.540297224083418\n"
     ]
    }
   ],
   "source": [
    "threshold = 8\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 17000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70, 519, 692, 1014, 464, 1193, 355, 939, 14174, 1336, 2247, 12964, 7045, 2067, 1972, 12028, 557, 2807, 2067, 8740, 4256, 7176, 1614, 519, 12965, 3648, 9179, 2773, 1336, 939], [13, 8, 233, 1237, 2934, 842, 241, 3260, 237, 420, 3122, 412, 69, 7, 1, 36, 1305, 130, 3, 12, 45, 39, 826, 147, 3260, 237, 780, 45, 99, 6921, 6597, 130, 91, 10464, 78, 2826, 842, 241], [347, 201, 340, 1280, 5216, 16618, 1092, 497, 10465, 249, 138, 27, 120, 1271, 89, 256, 1161, 5353, 290, 2879, 1298, 145, 2120, 1696, 85, 215, 2037, 936, 7177, 218, 2630, 1313]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27042\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 18813\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8229\n",
      "단어 집합에서 희귀 단어의 비율: 69.56955846461061\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.402908853209135\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 204, 1297, 1176, 7, 9007, 1201, 690, 882], [1, 200, 4, 5179, 12, 3738, 1144, 3, 2087, 125, 65], [1, 105, 450, 1409, 7564, 23, 7, 17300, 6, 1275, 4932], [1, 31, 871, 1575, 1372, 731, 151, 5, 4004], [1, 69, 217, 21, 5, 13650, 4338, 1202, 5768]]\n",
      "target\n",
      "decoder  [[204, 1297, 1176, 7, 9007, 1201, 690, 882, 2], [200, 4, 5179, 12, 3738, 1144, 3, 2087, 125, 65, 2], [105, 450, 1409, 7564, 23, 7, 17300, 6, 1275, 4932, 2], [31, 871, 1575, 1372, 731, 151, 5, 4004, 2], [69, 217, 21, 5, 13650, 4338, 1202, 5768, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 18000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 60452\n",
      "훈련 레이블의 개수 : 60452\n",
      "테스트 데이터의 개수 : 15112\n",
      "테스트 레이블의 개수 : 15112\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='pre')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='pre')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headline_max_len, padding='pre')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headline_max_len, padding='pre')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headline_max_len, padding='pre')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headline_max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 256\n",
    "hidden_size = 512\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 38)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 38, 256)      4352000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 38, 512), (N 1574912     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 38, 512), (N 2099200     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    4608000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 38, 512), (N 2099200     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  1574912     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 18000)  9234000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 25,542,224\n",
      "Trainable params: 25,542,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 38)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 38, 256)      4352000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 38, 512), (N 1574912     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 38, 512), (N 2099200     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    4608000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 38, 512), (N 2099200     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  1574912     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 512),  524800      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1024)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 18000)  18450000    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 35,283,024\n",
      "Trainable params: 35,283,024\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac7/aiffel/news_summarization/models/e11_abstractive'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/news_summarization/models/e11_abstractive'\n",
    "\n",
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2),\n",
    "      ModelCheckpoint(filepath = checkpoint_dir, save_weights_only=True, monitor='val_loss', mode='auto', save_best_only=True, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 6.3511\n",
      "Epoch 00001: val_loss improved from inf to 5.91628, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 66s 279ms/step - loss: 6.3511 - val_loss: 5.9163\n",
      "Epoch 2/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.9337\n",
      "Epoch 00002: val_loss improved from 5.91628 to 5.77397, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 66s 278ms/step - loss: 5.9337 - val_loss: 5.7740\n",
      "Epoch 3/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.7286\n",
      "Epoch 00003: val_loss improved from 5.77397 to 5.62849, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 66s 280ms/step - loss: 5.7286 - val_loss: 5.6285\n",
      "Epoch 4/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.5354\n",
      "Epoch 00004: val_loss improved from 5.62849 to 5.42989, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 70s 297ms/step - loss: 5.5354 - val_loss: 5.4299\n",
      "Epoch 5/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.2924\n",
      "Epoch 00005: val_loss improved from 5.42989 to 5.21071, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 71s 298ms/step - loss: 5.2924 - val_loss: 5.2107\n",
      "Epoch 6/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.0355\n",
      "Epoch 00006: val_loss improved from 5.21071 to 5.04020, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 68s 288ms/step - loss: 5.0355 - val_loss: 5.0402\n",
      "Epoch 7/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.7970\n",
      "Epoch 00007: val_loss improved from 5.04020 to 4.93647, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 291ms/step - loss: 4.7970 - val_loss: 4.9365\n",
      "Epoch 8/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.5730\n",
      "Epoch 00008: val_loss improved from 4.93647 to 4.80349, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 68s 287ms/step - loss: 4.5730 - val_loss: 4.8035\n",
      "Epoch 9/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.3592\n",
      "Epoch 00009: val_loss improved from 4.80349 to 4.66772, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 68s 288ms/step - loss: 4.3592 - val_loss: 4.6677\n",
      "Epoch 10/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.1519\n",
      "Epoch 00010: val_loss improved from 4.66772 to 4.57605, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 68s 288ms/step - loss: 4.1519 - val_loss: 4.5761\n",
      "Epoch 11/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.9549\n",
      "Epoch 00011: val_loss improved from 4.57605 to 4.53759, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 290ms/step - loss: 3.9549 - val_loss: 4.5376\n",
      "Epoch 12/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.7733\n",
      "Epoch 00012: val_loss improved from 4.53759 to 4.43975, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 290ms/step - loss: 3.7733 - val_loss: 4.4398\n",
      "Epoch 13/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.5959\n",
      "Epoch 00013: val_loss improved from 4.43975 to 4.40446, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 292ms/step - loss: 3.5959 - val_loss: 4.4045\n",
      "Epoch 14/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.4361\n",
      "Epoch 00014: val_loss improved from 4.40446 to 4.39190, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 291ms/step - loss: 3.4361 - val_loss: 4.3919\n",
      "Epoch 15/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.2803\n",
      "Epoch 00015: val_loss improved from 4.39190 to 4.37974, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 291ms/step - loss: 3.2803 - val_loss: 4.3797\n",
      "Epoch 16/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.1354\n",
      "Epoch 00016: val_loss improved from 4.37974 to 4.37126, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 70s 294ms/step - loss: 3.1354 - val_loss: 4.3713\n",
      "Epoch 17/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.9957\n",
      "Epoch 00017: val_loss improved from 4.37126 to 4.36913, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 292ms/step - loss: 2.9957 - val_loss: 4.3691\n",
      "Epoch 18/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.8616\n",
      "Epoch 00018: val_loss improved from 4.36913 to 4.36619, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive\n",
      "237/237 [==============================] - 69s 293ms/step - loss: 2.8616 - val_loss: 4.3662\n",
      "Epoch 19/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.7340\n",
      "Epoch 00019: val_loss did not improve from 4.36619\n",
      "237/237 [==============================] - 68s 289ms/step - loss: 2.7340 - val_loss: 4.3875\n",
      "Epoch 20/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.6071\n",
      "Epoch 00020: val_loss did not improve from 4.36619\n",
      "237/237 [==============================] - 68s 287ms/step - loss: 2.6071 - val_loss: 4.3986\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2df04ee750>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 학습 가중치 불러오기\n",
    "model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxx0lEQVR4nO3deVxU9f7H8deHTQRBRFFRQNx3xV1zN3NPM63MynazbM9uddtuv7vUva1aqVm22F6mZqWlZu6i4Y6KOyjuGygCsn1/f5yxkAAHmGEG+Dwfj3kwc853znw8jm+O3/M93yPGGJRSSpV9Hq4uQCmllGNooCulVDmhga6UUuWEBrpSSpUTGuhKKVVOaKArpVQ5YVegi0iQiMwWkTgR2Ski3fKs7yMiySKy2fZ4wTnlKqWUKoiXne0mAz8bY0aLiA/gl0+blcaYYfZ+cI0aNUxkZKS9zZVSSgEbNmw4ZYwJyW/dFQNdRAKBXsAdAMaYDCCjpEVFRkYSExNT0s0opVSFIiIJBa2zp8ulAXAS+EhENonIByLin0+7biKyRUQWikjLAgoZLyIxIhJz8uRJ+6pXSillF3sC3QtoD0wzxrQDLgBP52mzEahnjGkLvA3My29DxpgZxpiOxpiOISH5/o9BKaVUMdkT6IlAojFmne31bKyA/4Mx5pwxJsX2fAHgLSI1HFqpUkqpQl2xD90Yc0xEDolIU2PMLuBqYEfuNiJSGzhujDEi0hnrF8Vpp1SslKrQMjMzSUxMJD093dWlOJWvry9hYWF4e3vb/R57R7k8BHxuG+GyH7hTRCYAGGOmA6OB+0UkC0gDxhidxlEp5QSJiYkEBAQQGRmJiLi6HKcwxnD69GkSExOpX7++3e+zK9CNMZuBjnkWT8+1/h3gHbs/VSmliik9Pb1chzmAiFC9enWKOnhErxRVSpU55TnMLynOn7HMBfrxc+m89MN2MrNzXF2KUkq5lTIX6JsOnuWj1fG8sXi3q0tRSlVASUlJTJ06tcjvGzJkCElJSY4vKJcyF+iDWoVyc+cIpi/fx6o9p1xdjlKqgiko0LOzswt934IFCwgKCnJSVZYyF+gALwxrQcOQKjz2zWZOp1x0dTlKqQrk6aefZt++fURFRdGpUyf69u3L2LFjad26NQDXXXcdHTp0oGXLlsyYMeOP90VGRnLq1Cni4+Np3rw59957Ly1btmTAgAGkpaU5pDZ7hy26lco+nrx9cztGvLuaSd9uYebtnfDwKP8nSZRSl3vph+3sOHLOodtsUSeQF6/Nd/YSAF555RViY2PZvHkzy5YtY+jQocTGxv4xvPDDDz8kODiYtLQ0OnXqxKhRo6hevfpl29izZw9ffvkl77//PjfeeCPfffcdt956a4lrL5NH6ADNQwN5bmhzftt1ko/WxLu6HKVUBdW5c+fLxopPmTKFtm3b0rVrVw4dOsSePXv+8p769esTFRUFQIcOHYiPj3dILWXyCP2S27rWY+WeU7yycCdd6gfTqm5VV5eklCpFhR1JlxZ//z/nKly2bBlLlixh7dq1+Pn50adPn3yvaK1UqdIfzz09PR3W5VJmj9DBGqf5v1FtqO5fiYe/3MSFi1muLkkpVc4FBARw/vz5fNclJydTrVo1/Pz8iIuLIzo6ulRrK9OBDlDN34e3xkRx4PQF/jF/u6vLUUqVc9WrV6d79+60atWKJ5988rJ1gwYNIisrizZt2vD888/TtWvXUq1NXDXlSseOHY0jb3DxxqJdTFm6l8ljohgRVddh21VKuZedO3fSvHlzV5dRKvL7s4rIBmNM3qlYgHJwhH7Jw1c3pkO9ajw3N5aDp1NdXY5SSpW6chPoXp4eTB4TBQIPf7VJpwZQSlU45SbQAcKq+fHK9W3YfCiJN3VqAKVUBVOuAh1gaJtQbu4czrTl+1i9V6cGUEpVHOUu0AFeGNbSmhrga50aQClVcZTLQK/s48mUMe1ISsvkydlb0ZsnKaUqgnIZ6GDNx/DskOYsjTvBxzo1gFLKQYo7fS7AW2+9RWqq80bh2RXoIhIkIrNFJE5EdopItzzrRUSmiMheEdkqIu2dU27RjOtWj/7Na/HygjhiDye7uhylVDlQ5gMdmAz8bIxpBrQFduZZPxhobHuMB6Y5rMISEBFeHd2GYH8fnRpAKeUQuafPffLJJ3n11Vfp1KkTbdq04cUXXwTgwoULDB06lLZt29KqVSu+/vprpkyZwpEjR+jbty99+/Z1Sm1XnJxLRAKBXsAdAMaYDCAjT7MRwCxjdVZH247oQ40xRx1cb5FV8/fhzZuiGPtBNC/9sJ3/jW7r6pKUUo6y8Gk4ts2x26zdGga/UuDq3NPnLlq0iNmzZ7N+/XqMMQwfPpwVK1Zw8uRJ6tSpw08//QRYc7xUrVqVN954g99++40aNWo4tmYbe47QGwAngY9EZJOIfCAi/nna1AUO5XqdaFt2GREZLyIxIhJT1LtZl0S3htV5sG8jvolJZP6WI6X2uUqp8m3RokUsWrSIdu3a0b59e+Li4tizZw+tW7dmyZIlPPXUU6xcuZKqVUtnJlh7ps/1AtoDDxlj1onIZOBp4PlcbfK7u8RfhpYYY2YAM8Cay6Xo5RbfI1c3ZvXeUzw7ZxvtwoMID/YrzY9XSjlDIUfSpcEYwzPPPMN99933l3UbNmxgwYIFPPPMMwwYMIAXXnjB6fXYc4SeCCQaY9bZXs/GCvi8bcJzvQ4D3OpQ2JoaoN0fUwNof7pSqjhyT587cOBAPvzwQ1JSUgA4fPgwJ06c4MiRI/j5+XHrrbcyadIkNm7c+Jf3OsMVA90Ycww4JCJNbYuuBnbkaTYfGGcb7dIVSHZa/3nyYfjxMTi9r8hvDQ/247+jrKkBBk9eyfoDZ5xQoFKqPMs9fe7ixYsZO3Ys3bp1o3Xr1owePZrz58+zbds2OnfuTFRUFP/+97957rnnABg/fjyDBw922klRu6bPFZEo4APAB9gP3AncBGCMmS4iArwDDAJSgTuNMYXOjVvs6XO3z4U54yEnC1pcBz0ehdCinehct/80T87eyqGzqdzVvT5PDmyKr7dn0WtRSpU6nT634Olzy+Z86OePQfQ0+H0mZJyHhldDj8cgsgeIfTeLvnAxi1cWxvFpdAINQvx5/Ya2tIuoVrx6lFKlRgO9vM2HHlAbrnkJHouFq1+EY1vhk2HwQX/Y+SPkXHnqXP9KXvzzulZ8dncXLmbmMGraGv77cxwXs7JL4Q+glFKOVzYD/ZLKQdDzcXh0Gwx9HS6chK9vgaldYfMXkJV3uPxf9Whcg58f7ckNHcKZtmwfw99erVeVKuXmKsL8TMX5M5btQL/EuzJ0ugce2gijZoKnN8y7H6a0s7pmMi4U+vYAX2/+O7oNH93RiaS0DK57dzVvLt6tN8lQyg35+vpy+vTpch3qxhhOnz6Nr69vkd5XNvvQr8QY2LsEVr0JCauhcjB0uQ86jwe/4ELfmpyayT9+2M7cTYdpWSeQ129sS7Pagc6pUylVZJmZmSQmJpKenu7qUpzK19eXsLAwvL29L1te/k6KFsXBdbD6Ldi1ALz9ocMd0G0iVC38RtK/bD/Gs3O3kZyWyaP9m3BfrwZ4eZaP/9Aopcquih3ol5zYCavegm3fgnhA25ugx+NQvWGBbzlzIYPn58Xy07ajtA0P4vUb2tKoZpXSq1kppfLQQM8t6SCseRs2zoLsDGg5Eno+AbVaFviWH7Yc4fnvY0nLyObJgU25s3t9PD3sGx6plFKOpIGen5QTsPZd+P0DyEiBJoOh1yQIy3c/ceJ8On+fE8uSncfpFFmNV0a1oWGIHq0rpUqXBnph0s7Cuhmwbpr1vH5v64i9fq+/XKRkjGHupsP8Y/520rNyeLhfI8b3aoiPl/atK6VKhwa6PS6mwIaPrO6YlOMQ1gl6ToImA/8S7CfOp/PSDzv4aetRmtYK4OVRrWmvV5kqpUqBBnpRZKbD5s9g1WRIPgi1WlkXL7W4Djwun+9lyY7jPP99LMfOpTOuaz2eHNSMKpXsmZFYKaWKRwO9OLIzYdtsWPUGnNoNwQ2t+WLa3ARePn80S7mYxWu/7OKTtfHUDvTlnyNa0b9FLRcWrpQqzzTQSyInG3b+ACtft+aMCQyzZnjscId1RarNxoNnefq7rew+nsLQ1qG8OLwFNQOKdpWXUkpdiQa6I1y6+nTFa3AoGmq3gRHvQmibP5pkZOXw3vJ9vL10L77eHvx9SHNu6hSO2DkDpFJKXYkGuiMZYx2x//QEpJ2xumF6PQlelf5osu9kCs/M2cb6A2foUj+Yl69vTQMd4qiUcoDyN32uK4lAi+EwcR20vgFWvArv9YLEP385NQypwlf3duXl61uz4+g5Bk1eyTtL95CRpZN9KaWcRwO9uPyCYeR0uGU2XDwPM6+BX56FjFQAPDyEmztH8OvjvenfvCavLdrNtW+vYtPBsy4uXClVXtkV6CISLyLbRGSziPyln0RE+ohIsm39ZhFx/u2t3UXja+CBaOsk6dp3YNpVEL/qj9U1A32ZeksH3h/XkeS0TK6ftsa6MClTb6ShlHKsohyh9zXGRBXUdwOstK2PMsb8nyOKKzN8A2HYm3D7j4CBj4fCj49bR+4217SoxeLHezGuaz0+WRvPqGlrSDyb6rqalVLljna5OFL9nnD/Gug6EWI+hKndrJExNgG+3rw0ohUfjOvIwdOpDH9nNWv2nXJhwUqp8sTeQDfAIhHZICLjC2jTTUS2iMhCEcl36kIRGS8iMSISc/LkyWIV7PZ8/GHQf+DuReDtB5+NgnkPWPPE2FzdvBbzHuxONT9vbpu5ng9XHSjXd19RSpUOu4YtikgdY8wREakJLAYeMsasyLU+EMgxxqSIyBBgsjGmcWHbLLPDFosiMx1W/M+ah92/Bgx9A5oP+2P1+fRMHv9mC4t3HOf6dnX5z/Wt8fX2LHh7SqkKr8TDFo0xR2w/TwBzgc551p8zxqTYni8AvEWkRomqLg+8feHqF2D8b+Bf07qB9bd3wgWrmyXA15v3bu3AY/2bMGfTYUZPX8PhpDQXF62UKquuGOgi4i8iAZeeAwOA2DxtaovtckgR6Wzb7mnHl1tGhba1Qr3fcxD3I7zTCeJ+AqzhjY/0b8wH4zqScCqV4W+vYu0+3XVKqaKz5wi9FrBKRLYA64GfjDE/i8gEEZlgazMaiLW1mQKMMdopfDlPb+uK0vtWQlA4fDXWGgmTaR2R929h9atX9fPm1pnr+Gi19qsrpYpGL/13hawM+PUla9x6SHMYPfOPW+CdS8/k8a+3sGTnca5vX5f/jNR+daXUn/TSf3fj5QMD/w23zoHU0zCjL6x/H4wh0NebGbd14NH+jZmz8TA3TF/LEe1XV0rZQQPdlRpdbY1bb9AbFkyCL2+GC6fx8BAe7d+EGbd14MCpC1z79iqi92u/ulKqcBrorlYlBMZ+A4NegX2/WlMH7F8GwICWtZk30dav/sE6PlkTr/3qSqkCaaC7AxHoej/c86s1jcCs62Dxi5CdSaOaVZg3sTu9m4Tw4vztPDl7q84Do5TKlwa6OwltA+OXQftxsPotmDkAzuwn0Neb98d15OGrGzN7QyI3vreWY8nprq5WKeVmNNDdjY8/DJ8CN3wCZ/bB9J6w5Ss8PITHr2nCe7d1YN+JFEa8u4rYw8murlYp5UY00N1Vy+tgwmrrVndz74Pv7oX0cwxsWZvZ91+Fpwg3TF/LL9uPubpSpZSb0EB3Z0HhcMeP0OfvEDsb3usJiTE0Dw1k3oPdaVI7gAmfbeC95fv0ZKlSSgPd7Xl4Qp+n4M6FkJMNHw6Ela9T08+Lr8d3ZUirUF5eGMfT323TW9wpVcFpoJcVEV1hwipofi38+n8wvTu+8Ut5e0wUD/VrxNcxh7j9w/Ukp2a6ulKllItooJcllYNg9Edw02eQnQGfj8bji1E80TaLN25sy4aEs4ycupoDpy64ulKllAtooJc1ItZR+gPrYODLcHgjTO/B9Ydf5atbGnA2NYORU1frlaVKVUAa6GWVlw90ewAe3gSd74NNn9F+Xj+WdtlIqJ/htpnr+DbmkKurVEqVIg30ss4vGAa/Yh2xN+hDtbUv85PH4zxaaytPzt7Cf3+OIydHR8AoVRFooJcXNRrBmM/h9h/x8Atm4pmXWRn8L9YvX8ADn28kLUOnC1CqvNNAL2/q94Txy+G6aYR5JvFdpZe4dvczPDR1DsfP6XQBSpVnGujlkYcHRI1FHtoAfZ5hkM9Wpp6dwOLJ97HzwEFXV6eUchK7Al1E4kVkm4hsFpG/3GZILFNEZK+IbBWR9o4vVRWZjz/0eRrPRzaS2nQkY7O/p9bHVxH3/WtwMcXV1SmlHKwoR+h9jTFRBdz6aDDQ2PYYD0xzRHHKQQLrEDT2A5JuXUyiTyTNNv2TzP82wHxzO+yY/8d9TZVSZZuXg7YzAphluzF0tIgEiUioMeaog7avHCC4UScqT1rG5M8/p9r+H7gubhmBO+aBTxVoNhRaXg8N+1lDIpVSZY69gW6ARSJigPeMMTPyrK8L5B70nGhbpoHuZipX8uLhO8fx8ZpedPoplmGB+3ghcidVd/8MW78G3yDrwqVW10NkL/B01O98pZSz2fuvtbsx5oiI1AQWi0icMWZFrvWSz3v+MvhZRMZjdckQERFR5GKVY4gId3avT8s6VXng88p029GMV69/hqF+uyB2DmyfB5s+Bb8a0GIEtBoFEd2sk61KKbclRZ12VUT+AaQYY17Ltew9YJkx5kvb611An8K6XDp27GhiYv5yflWVsuPn0nng841sSDjLPT3q8/TgZnjlXIS9SyD2O9j1M2SlQUAotBxpdcuEdbSmIFBKlToR2VDAucwrnxQVEX8RCbj0HBgAxOZpNh8YZxvt0hVI1v7zsqFWoC9f3tuVcd3q8cGqA9zywTpOpntY3S43fAxP7oVRM6FuB/j9A5jZHya3gZVvQOoZV5evlMrlikfoItIAmGt76QV8YYz5t4hMADDGTBcRAd4BBgGpwJ3GmEIPv/UI3f3M2ZjIM3O2Uc3Ph6m3tqd9RLXLG6QnQ9wC2PIFHFgBXpUh6mbocj+ENHFN0UpVMIUdoRe5y8VRNNDd0/YjyUz4bAPHktN58dqW3NIlAsmve+X4doieBlu/geyL0Kg/dH3AGiWj3TFKOY0GuiqSpNQMHvlqM8t3n2R0hzD+dV0rfL0982984RTEfGh1x6Qch5Bm0GUCtLkJfPxKt3ClKgANdFVk2TmGyUt2M2XpXlrVDWTaLR0IDy4koLMuwva5sPZdOLYVKgdDxzuh0z0QWKf0CleqnNNAV8W2ZMdxHvtmM54ewpQx7ejVJKTwNxgDB9dawR73k3VP1JYjoev91olVpVSJaKCrEjlw6gITPt3A7hPnmTSgKff3boiHhx395GcOwPr3YeMsyDgP4V2sfvZmw/SCJaWKSQNdlVhqRhZPfbeNH7YcYUCLWrx6Q1uqVva2783p52DzF7BuGpyNh6rh0OU+aD8OfKs6tW6lyhsNdOUQxhg+XB3PfxbsJLSqL++MbU9UeJD9G8jJht2/WN0xCavAJ8AK9a4TIEivHFbKHhroyqE2JJzl4S83cfxcOk8NasbdPerb1wWT25FNVrDHzrFetxgO3R6CMO1nV6owGujK4ZJTM/nbd1v4Zftx+jYN4bUb2lK9SqVibCgR1r0HGz6Bi8nWnDHdJkLTIdYJVaXUZTTQlVMYY/g0OoF//biTav7evHVTO7o1rF68jV08D5s+g+ipkHQQqtW3TqBGjYVKVRxbuFJlmAa6cqrtR5J56ItNxJ++wMNXN+ahfo3xLGoXzCXZWRD3I6x9BxJ/t6bz7XgndL4PAkMdWrdSZZEGunK6lItZvDAvljmbDtO1QTCTx7SjVqBvyTZ6cJ0V7HE/gnha0/h2mwihbRxTtFJlkAa6KjWzNyTy/LxYKvt48vqNbenbtGbJN3rmAKybDhs/hcwLENkT2twIjQdCQK2Sb1+pMkQDXZWqvSdSePCLjcQdO8/4Xg2YNKApPl4OuDlG2lnr5OnvMyH5oLWsbgdoOhiaDIZaLXViMFXuaaCrUpeemc2/ftrBZ9EHaRsexDs3tyt8LpiiMMaa7XHXQti9EA5vsJZXjYCmg6DJIIjsAV7FGHWjlJvTQFcus2DbUZ76bisA/x3VhiGtnXBi8/wx64Kl3T/Dvt+sOyz5BECjftaRe+MB4F/M0TdKuRkNdOVSh86k8tCXm9h8KIlbukTw/LAWBU/HW1KZabB/uXXkvutnSDkG4mHNI3Opa6ZGY+2aUWWWBrpyuczsHF77ZRfvrdhPs9oBvH1zOxrXCnDuh+bkwNHN1pH7rgVwbJu1vFp9q789KAKC6lk/q9l+VnJyTUqVkAa6chu/7TrBpG+2kHIxi2cGN+P2qyLzvyOSMyQnWuG+dymc2Q9JCZCZenmbysG2oL8U8vX+DP2gCL1ph3I5hwS6iHgCMcBhY8ywPOv6AN8DB2yL5hhj/q+w7WmgV1wnzqfz1Oyt/LbrJL2bhPDq6DbULOmY9eIwBlJPw9kEK9yTEqyrVM/afiYdtG6vl5t/CFSLhAZ9rBtp126j3TeqVDkq0B8HOgKBBQT6pLzLC6OBXrEZY/gsOoF//bQT/0pevHx9awa2rO3qsi6XkwMXTuQK+Hjr58ndkLgeTI519N78WmgxAup2BA8HDM9UqhCFBbpddxkQkTBgKPBv4HEH1qYqKBHhtm6RdGtYnUe/3sx9n25gTKdwnh/WAv9KbnLzCw8PCKhtPSK6XL7uwimrX37HfGtysbXvQECodfOO5tdCve56Ew9V6uw6QheR2cDLQAD5HInbjtC/AxKBI7Y22/PZznhgPEBERESHhISEEpavyoOMrBzeWrKbacv3US/YjzdviqJdRDVXl2W/9GRr2OTO+bBniTVs0q+6NWNk8+HQoLeOiVcOU6IuFxEZBgwxxjxQUNeKiAQCOcaYFBEZAkw2xjQubLva5aLyWrf/NI9/s4Vj59J5uF9jJvZtiJdnGevCyLgAe3+1wn33L3DxHFQKhCYDrSP3Rv3Bx9/VVaoyrKSB/jJwG5AF+AKBWCc9by3kPfFAR2PMqYLaaKCr/JxLz+TF77czd9Nh2kcE8eZNUdSrXkYDMOuiNSZ+53zrhtlpZ8CrMjS6Gmq1gqp1oWqYdUu+wLo6gkbZxWHDFgs5Qq8NHDfGGBHpDMwG6plCNq6Brgozf8sRnp27jZwcw4vDW3JDh7DSG97oDNlZcHCN1ee+5xdIOgTk+efhV90K9qrhtqAPs4W+7XWVWnrTD1Xyk6IFbHQCgDFmOjAauF9EsoA0YExhYa7UlQxvW4cO9arxxDeb+dvsrSzdeYKXr29NNX8fV5dWPJ5eUL+X9eA1yM6Ec0essfHJiXAu8c/nZw9A/CrrDk65eXhBQB0r5H2rgndl8Pa3juwvPfeubHt96bk/ePvlep7rPV6+OuTSUXKyrauUM9OscyiZ6dY1Dlm2n5e9TrOGu+Y90e4AemGRcms5OYb3V+7ntUW7qObnw+s3tqVn4xBXl1U60pMh+bAt6A/BuUvPD0PGechItYVFqvU875h5e3jn+WXgXdla9scviQLWe1WyHp6VwMvH9rOwZT5/rnO30T/GWOc+0s7a8UiyfmZesAV4uhXg2RlF+8yrHoYB/yxWuXqlqCrzth9J5tGvNrPnRAp3da/P3wY1dd58MGVVTvaf4X4p6DPTrLDKHfy51/3RJu+y3O+1HXlmXrDG3peUeFj/20Cs5388xPawvc53fe6fnrZteeZ6LXle516f65E3wHMyC67XsxL4BUPlatbDN8i6LaKX75+/5Lwq53rum+e5H3jbfl5aVynA+lmc3aeBrsqD9MxsXlkYx8dr4mlUswpv3NiWNmFBri6r4jDGOhLNuGD9zLqY6+dFyMqwuhQKWpe7jcn584Gxtp17mcnJZ5mx2uZk51pme56TbWuf+/Wl9SbP6xzwqfJnQP/xCMpnWbViB6+zaKCrcmXF7pP8bfZWTqZcZGLfRjzUrxHeZW14o1LFVFig678CVeb0ahLCL4/2YkTbOkz5dQ8jp65m9/Hzri5LKZfTQFdlUlU/b964KYrpt7bnaFI6w95exYwV+8jO0cFVquLSQFdl2qBWofzyWC/6NAnhPwviuHlGNAdPp175jUqVQxroqsyrUaUS793WgddvaMvOo+cYNHkFn69LQC+FUBWNBroqF0SEUR3C+OWxXrSPqMazc2O5/aPfOZac7urSlCo1GuiqXKkTVJlZd3XmnyNa8vuBMwx4cznzNh3Wo3VVIWigq3LHw8Oaa33BIz1pVLMKj369mQc+38jplGJcSalUGaKBrsqt+jX8+XbCVTw1qBm/7jzBwLdWsHjHcVeXpZTTaKCrcs3TQ7i/T0PmP9SdkABf7p0Vw6Rvt5CcVsil3kqVURroqkJoVjuQ7yd258G+jZizMZEBby7Xo3VV7migqwrDx8uDSQObMm9id6r5+XDvrBge/GIjp7RvXZUTGuiqwmkTFsT8B3vwxDVNWLT9OP3fWM7cTYk6EkaVeRroqkLy8fLgoasb89PDPahfw5/Hvt7CXR//zpGkNFeXplSxaaCrCq1xrQBmT7iKF4a1IHr/GQa8uYJPoxPI0TlhVBlkd6CLiKeIbBKRH/NZJyIyRUT2ishWEWnv2DKVch5PD+GuHvVZ9FgvosKDeH5eLGPej+bAqQuuLk2pIinKEfojwM4C1g0GGtse44FpJaxLqVIXHuzHp3d35n+j2lhzwry1gunL95GV7YC79ChVCuwKdBEJA4YCHxTQZAQwy1iigSARCXVQjUqVGhHhxk7hLHm8N72bhPDKwjium7qaHUfOubo0pa7I3iP0t4C/AQUdqtQFDuV6nWhbdhkRGS8iMSISc/LkyaLUqVSpqhXoy3u3deDdse05lpzO8HdW8fqiXVzMynZ1aUoV6IqBLiLDgBPGmA2FNctn2V/OKhljZhhjOhpjOoaEVJA7t6syS0QY2iaUxY/1ZnhUHd5eupehU1axIeGsq0tTKl/2HKF3B4aLSDzwFdBPRD7L0yYRCM/1Ogw44pAKlXKxav4+vHFjFB/f2Ym0jGxGT1/Ds3O3kZSa4erSlLrMFQPdGPOMMSbMGBMJjAGWGmNuzdNsPjDONtqlK5BsjDnq+HKVcp0+TWvyy2O9uOOqSL5cf5C+ry3jy/UHdYijchvFHocuIhNEZILt5QJgP7AXeB94wAG1KeV2qlTy4sVrW/LTw9bUvM/M2cbIqavZcijJ1aUphbjqcueOHTuamJgYl3y2Uo5gjGHe5sP8Z0Ecp1IuMqZTBH8b2JRq/j6uLk2VYyKywRjTMb91eqWoUsUkIoxsF8bSJ3pzV/f6fBNziL6vL+PzdQlkazeMcgENdKVKKMDXm+eHteCnh3vQpFYAz86NZeTU1WzWbhhVyjTQlXKQZrUD+Xp8VyaPieJYcjojp67m6e+2cuaCjoZRpUMDXSkHEhFGRNXl1yd6c3f3+ny7IZG+ry3js2jthlHOp4GulBME+Hrz3LAWLHykJ81DA3huXiwj3l3FxoN6UZJyHg10pZyoSa0Avry3K1NubsfJ8xe5fuoa/jZ7i94lSTmFBrpSTiYiDG9bh1+f6MP4Xg2Ys/EwfV9bxsxVB8jUmRyVA2mgK1VKqlTy4u9DmvPzoz2JCg/inz/uYPDklazcoxPVKcfQQFeqlDWqGcCsuzrz/riOZGTlcNvM9YyfFcPB06muLk2VcRroSrmAiHBNi1oseqwXTw5syso9p+j/5nJeX7SL1IwsV5enyigNdKVcyNfbk4l9G7F0Um8Gt6rN20v3cvXry5m/5QiumpZDlV0a6Eq5gdCqlZk8ph3fTuhGsL8PD3+5iZvei2b7kWRXl6bKEA10pdxIp8hg5j/Yg/+MbM2eE+e59u1VPDt3m15tquyiga6Um/H0EMZ2iWDZpL6M6xbJV78fou9ry5i1Nl5vWK0KpYGulJuq6ufNP4a3ZMHDPWlZJ5AXvt/OsLdXsXbfaVeXptyUBrpSbq5p7QA+v6cL029tz/n0LG5+P5p7PvmduGPnXF2acjMa6EqVASLCoFah/PpEb54c2JR1B84wePJKHv1qEwmnL7i6POUm9I5FSpVBSakZTF++n4/XHCAr23BTp3AevroxtQJ9XV2acrLC7lh0xUAXEV9gBVAJ8AJmG2NezNOmD/A9cMC2aI4x5v8K264GulIld+JcOlOW7uGr9Yfw8hRuvyqS+3s3JMhPb4NXXpU00AXwN8akiIg3sAp4xBgTnatNH2CSMWaYvUVpoCvlOAmnL/Dm4t18v+UIVSp5cV+vBtzZvT7+lbxcXZpysBLdU9RYUmwvvW0PvYRNKTdSr7o/b41px8JHetKlfnVeW7Sb3q/+xserD3AxK9vV5alSYtdJURHxFJHNwAlgsTFmXT7NuonIFhFZKCItC9jOeBGJEZGYkyd1hjmlHK1Z7UA+uL0j391/FY1qVuEfP+yg32vLmb0hUe+YVAEU6aSoiAQBc4GHjDGxuZYHAjm2bpkhwGRjTOPCtqVdLko5lzGGlXtO8eovu9h2OJlGNaswaUATBrasjdWTqsqiEnW55GaMSQKWAYPyLD93qVvGGLMA8BaRGsWqVinlECJCryYhzH+wO1NvaU+OMUz4bCPXvbuaFbtP6uRf5dAVA11EQmxH5ohIZaA/EJenTW3byVNEpLNtu3o5m1JuQEQY0jqURY/24n+j23AqJYNxH67npveiWbdf/5mWJ/acAg8FPhERT6yg/sYY86OITAAwxkwHRgP3i0gWkAaMMfrrXym34uXpwY0dwxkRVYevfz/EO0v3ctOMaHo0qsHjA5rQPqKaq0tUJaQXFilVQaVnZvNZdALTlu3j9IUM+jWryePXNKFV3aquLk0VokTj0J1FA10p93DhYhYfr4lnxor9JKdlMqhlbR67pglNawe4ujSVDw10pdQVnUvPZObKA3y46gApGVkMa1OHR/s3pmFIFVeXpnLRQFdK2S0pNYMZK/bz0ep4LmZlM7JdGI9c3ZiI6n6uLk2hga6UKoZTKReZvmwfn0YnkJ1juKFjOA/1a0SdoMquLq1C00BXShXb8XPpvPvbXr5cfxDBupvS/X0a6syOLqKBrpQqscSzqbyzdC/fbkjEU4RRHcK4v3dD7YopZRroSimHOXg6lfdW7OPbmESycnIY3rYO9/dppKNiSokGulLK4Y6fS+eDlfv5fN1BUjOyGdCiFhP7NqJteJCrSyvXNNCVUk5z9kIGH62J5+PVBziXnkWPRjWY2LcRXRsE6yRgTqCBrpRyupSLWXwencD7Kw9wKuUi7SOCmNi3Ef2a1dRgdyANdKVUqUnPzObbmENMX76fw0lpNKsdwMS+jRjSOhRPDw32ktJAV0qVuszsHOZvPsLUZXvZd/IC9Wv4M6F3A0a2C8PHq0gzd6tcNNCVUi6Tk2P4Zfsx3l22l9jD5wit6ss9PRswplO43vO0GDTQlVIuZ4xhxZ5TvPvbXtYfOEOgrxe3davHHVfVJySgkqvLKzM00JVSbmXjwbPMWL6fX3Ycw9vTg1Htw7i3Z30a6ERgV6SBrpRyS/tPpvDBqgPM3pBIZnYOA1vU5r7eDWinN9sokAa6UsqtnTx/kU/WxDNrbTzn0rPoHBnMfb0b0LdpTTx0ZMxlShToIuILrAAqYd2ybrYx5sU8bQSYDAwBUoE7jDEbC9uuBrpSKq8LF7P4+vdDzFx1gMNJaTSuWYXxvRowIqqujoyxKWmgC+BvjEkREW9gFfCIMSY6V5shwENYgd4FmGyM6VLYdjXQlVIFyczO4aetR5m+fB9xx85TK7ASd3Wvz81dIgj09XZ1eS5VWKBf8VeesaTYXnrbHnl/C4wAZtnaRgNBIhJakqKVUhWXt6cH17Wry8JHevLJXZ1pGFKFlxfG0f3lpby8cCfHktNdXaJbsmsQqIh4AhuARsC7xph1eZrUBQ7lep1oW3Y0z3bGA+MBIiIiilmyUqqiEBF6Nwmhd5MQtiUm896Kfby/Yj8zVx5gWJtQ7u7RgNZhelPrS+wKdGNMNhAlIkHAXBFpZYyJzdUkv7MWf+nLMcbMAGaA1eVS9HKVUhVV67CqvDO2PYfOpPLR6ni+iTnEvM1H6BwZzN0969O/ea0KP7VAkc4yGGOSgGXAoDyrEoHwXK/DgCMlKUwppfITHuzHC9e2YM0z/XhuaHMOJ6Vx36cb6PvaMj5afYCUi1muLtFlrhjoIhJiOzJHRCoD/YG4PM3mA+PE0hVINsYcRSmlnCTQ15t7ejZg+ZN9mHpLe0ICKvHSDzvo9vKv/GfBTg4npbm6xFJnT5dLKPCJrR/dA/jGGPOjiEwAMMZMBxZgjXDZizVs8U4n1auUUpfx8vRgSOtQhrQOZfOhJGauOvDHY1Cr2tzdoz7tK8iFSnphkVKq3DmclMasNfF8sf4g59OzaBcRxD09GjCwZS28PMv2eHa9UlQpVSFduJjF7A2JfLj6AAmnU6kbVJk7rorkxk7hVK1cNseza6ArpSq07BzDrzuPM3PVAdYdOENlb09Gtq/LuG71aFY70NXlFYkGulJK2cQeTubTtQnM23yYi1k5dK4fzLhu9RjYsjbeZaA7RgNdKaXySErN4JuYQ3wancChM2nUDKjE2C4RjO0cQc1AX1eXVyANdKWUKkB2jmH57hN8siaB5btP4uUhDGpVm9uviqRjvWpud4PrwgJd7/+klKrQPD2Efs1q0a9ZLQ6cusBn0Ql8G3OIH7cepVntAG6/KpIRUXXw83H/uNQjdKWUyiM1I4vvNx/hkzXxxB07T4CvFzd2DOe2rvWIrOHv0tq0y0UppYrBGENMwlk+WRPPz7HHyMox9G4Swrhu9ejTtKZL5o7RLhellCoGEaFTZDCdIoM5cS6dL9Yf5It1B7n7kxjCgytzS5d63NQxnGr+Pq4uFdAjdKWUKpLM7Bx+2X6MWWsTWH/gDD5eHgxvW4dx3erRJizI6Z+vXS5KKeUEccfO8enaBOZuOkxqRjZtw4O4vVs9hrQOxdfb0ymfqYGulFJOdC49k+82JPJpdAL7T14g2N+HmzqFc0uXCMKq+Tn0szTQlVKqFBhjWL33NLPWxrNk53EA+jWrxbhu9ejRqAYeDjiJqidFlVKqFIgIPRrXoEfjGhxOSuOLdQl8tf4QS3Yep0ENf27tWo9RHcKcNjGYHqErpZQTXczKZsG2o8xam8Cmg0lU9vbkiQFNuKdng2JtT4/QlVLKRSp5eTKyXRgj24UReziZWWvjqRNU2SmfpYGulFKlpFXdqvxvdFunbd+ee4qGi8hvIrJTRLaLyCP5tOkjIskistn2eME55SqllCqIPUfoWcATxpiNIhIAbBCRxcaYHXnarTTGDHN8iUoppexxxSN0Y8xRY8xG2/PzwE6grrMLU0opVTRFuj2HiEQC7YB1+azuJiJbRGShiLR0RHFKKaXsZ/dJURGpAnwHPGqMOZdn9UagnjEmRUSGAPOAxvlsYzwwHiAiIqK4NSullMqHXUfoIuKNFeafG2Pm5F1vjDlnjEmxPV8AeItIjXzazTDGdDTGdAwJCSlh6UoppXKzZ5SLADOBncaYNwpoU9vWDhHpbNvuaUcWqpRSqnD2dLl0B24DtonIZtuyvwMRAMaY6cBo4H4RyQLSgDHGVZegKqVUBeWyS/9F5CSQUMy31wBOObAcR3P3+sD9a9T6SkbrKxl3rq+eMSbfPmuXBXpJiEhMQXMZuAN3rw/cv0atr2S0vpJx9/oKUqRhi0oppdyXBrpSSpUTZTXQZ7i6gCtw9/rA/WvU+kpG6ysZd68vX2WyD10ppdRfldUjdKWUUnlooCulVDnh1oEuIoNEZJeI7BWRp/NZLyIyxbZ+q4i0L8Xa3H6eeBGJF5Ftts/+y/3+XLz/mubaL5tF5JyIPJqnTanvPxH5UEROiEhsrmXBIrJYRPbYflYr4L2Ffl+dWN+rIhJn+zucKyJBBby30O+DE+v7h4gczvX3OKSA97pq/32dq7b4XBdQ5n2v0/dfiRlj3PIBeAL7gAaAD7AFaJGnzRBgISBAV2BdKdYXCrS3PQ8AdudTXx/gRxfuw3igRiHrXbb/8vm7PoZ1wYRL9x/QC2gPxOZa9j/gadvzp4H/FvBnKPT76sT6BgBetuf/za8+e74PTqzvH8AkO74DLtl/eda/Drzgqv1X0oc7H6F3BvYaY/YbYzKAr4ARedqMAGYZSzQQJCKhpVGcKR/zxLts/+VxNbDPGFPcK4cdxhizAjiTZ/EI4BPb80+A6/J5qz3fV6fUZ4xZZIzJsr2MBsIc/bn2KmD/2cNl++8S23xUNwJfOvpzS4s7B3pd4FCu14n8NTDtaeN0bjxPvAEWicgG29TFebnF/gPGUPA/IneYZ7+WMeYoWL/IgZr5tHGXfXkX1v+68nOl74MzPWjrEvqwgC4rd9h/PYHjxpg9Bax35f6zizsHuuSzLO8YS3vaOJXYN098W+BtrHniS1N3Y0x7YDAwUUR65VnvDvvPBxgOfJvPalfvv6Jwh335LNYtIz8voMmVvg/OMg1oCEQBR7G6NfJy+f4Dbqbwo3NX7T+7uXOgJwLhuV6HAUeK0cZpxEHzxDuLMeaI7ecJYC7Wf2tzc+n+sxkMbDTGHM+7wtX7L5fjl7qibD9P5NPG1d/F24FhwC3G1uGblx3fB6cwxhw3xmQbY3KA9wv4XFfvPy/geuDrgtq4av8VhTsH+u9AYxGpbzuKGwPMz9NmPjDONlqjK5B86b/Gzmbrb3PbeeJFxF+sm3ojIv5YJ85i8zRz2f7LpcCjIlfuvzzmA7fbnt8OfJ9PG3u+r04hIoOAp4DhxpjUAtrY831wVn25z8uMLOBzXbb/bPoDccaYxPxWunL/FYmrz8oW9sAahbEb6+z3s7ZlE4AJtucCvGtbvw3oWIq19cD6L+FWYLPtMSRPfQ8C27HO2EcDV5VifQ1sn7vFVoNb7T/b5/thBXTVXMtcuv+wfrkcBTKxjhrvBqoDvwJ7bD+DbW3rAAsK+76WUn17sfqfL30Pp+etr6DvQynV96nt+7UVK6RD3Wn/2ZZ/fOl7l6ttqe+/kj700n+llCon3LnLRSmlVBFooCulVDmhga6UUuWEBrpSSpUTGuhKKVVOaKArpVQ5oYGulFLlxP8DTS3XyTeyMQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ validation loss가 2회 이상 감소하지 않는 지점에서 학습을 멈추고 그 이전 가장 낮은 loss를 얻은 때의 가중치를 불러왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 인퍼런스 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headline_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : former american boxer floyd mayweather lost temper judges event mayweather daughter participant mayweather claimed judges cheated caused daughter team lose finish second youth competition mayweather also reportedly mentioned funded competition \n",
      "실제 요약 : mayweather shouts at judges after daughter loses competition \n",
      "예측 요약 :  mcgregor got his own final after his own last fight\n",
      "\n",
      "\n",
      "원문 : claiming person behind hoax hijack note jet airways flight identified union civil aviation minister ashok gajapathi raju said advised airlines put fly list immediately per reports man named confessed left note destabilise operations delhi bound flight \n",
      "실제 요약 : man behind hoax hijack note identified put on no fly list \n",
      "예측 요약 :  air india flight delayed over cr for poor in india\n",
      "\n",
      "\n",
      "원문 : bjp performance assembly polls arrogance nationalist congress party tuesday said hinted farewell nda government lok sabha elections face defeat bjp ncp chief spokesperson said government moves like gst demonetisation bearing polls outcome added \n",
      "실제 요약 : bjp poll performance predicts its farewell in ncp \n",
      "예측 요약 :  bjp allies alliance with pdp alliance for lok sabha polls\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(70, 73):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 말도 안되는 요약만 하고 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 패딩을 바꾸면 도움이 될까 싶어 패딩을 바꿔봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/news_summarization/data/preprocessed_news.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "data = data.iloc[:,1:3]\n",
    "# 최대 길이 \n",
    "text_max_len = 38\n",
    "summary_max_len = 11\n",
    "# 최대 길이 이상 데이터 제거\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len and len(x.split()) != 1)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "# 인코더, 디코더 입력, 레이블 설정\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "# 데이터 셔플\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "# 전체 데이터의 20%를 validation dataset으로 배정\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "# 입력 데이터 토큰화\n",
    "src_vocab = 17000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "# 타켓 데이터 토큰화\n",
    "tar_vocab = 18000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "# 포스트 패딩\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 38)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 38, 128)      2176000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 38, 256), (N 394240      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 38, 256), (N 525312      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 128)    2304000     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 38, 256), (N 525312      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 256),  394240      embedding_5[0][0]                \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_10[0][0]                    \n",
      "                                                                 lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_11[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 18000)  9234000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,684,432\n",
      "Trainable params: 15,684,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout = 0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout = 0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 6.6163\n",
      "Epoch 00001: val_loss improved from inf to 6.10432, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 386ms/step - loss: 6.6163 - val_loss: 6.1043\n",
      "Epoch 2/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 6.0738\n",
      "Epoch 00002: val_loss improved from 6.10432 to 5.84121, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 386ms/step - loss: 6.0738 - val_loss: 5.8412\n",
      "Epoch 3/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.7024\n",
      "Epoch 00003: val_loss improved from 5.84121 to 5.45561, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 384ms/step - loss: 5.7024 - val_loss: 5.4556\n",
      "Epoch 4/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.2771\n",
      "Epoch 00004: val_loss improved from 5.45561 to 5.13164, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 92s 388ms/step - loss: 5.2771 - val_loss: 5.1316\n",
      "Epoch 5/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.8873\n",
      "Epoch 00005: val_loss improved from 5.13164 to 4.87884, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 385ms/step - loss: 4.8873 - val_loss: 4.8788\n",
      "Epoch 6/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.5625\n",
      "Epoch 00006: val_loss improved from 4.87884 to 4.72386, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 386ms/step - loss: 4.5625 - val_loss: 4.7239\n",
      "Epoch 7/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.2863\n",
      "Epoch 00007: val_loss improved from 4.72386 to 4.60089, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 92s 388ms/step - loss: 4.2863 - val_loss: 4.6009\n",
      "Epoch 8/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.0462\n",
      "Epoch 00008: val_loss improved from 4.60089 to 4.51548, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 93s 394ms/step - loss: 4.0462 - val_loss: 4.5155\n",
      "Epoch 9/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.8378\n",
      "Epoch 00009: val_loss improved from 4.51548 to 4.45799, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 92s 388ms/step - loss: 3.8378 - val_loss: 4.4580\n",
      "Epoch 10/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.6524\n",
      "Epoch 00010: val_loss improved from 4.45799 to 4.42030, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 93s 394ms/step - loss: 3.6524 - val_loss: 4.4203\n",
      "Epoch 11/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.4861\n",
      "Epoch 00011: val_loss improved from 4.42030 to 4.39007, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 93s 393ms/step - loss: 3.4861 - val_loss: 4.3901\n",
      "Epoch 12/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.3358\n",
      "Epoch 00012: val_loss improved from 4.39007 to 4.36364, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 382ms/step - loss: 3.3358 - val_loss: 4.3636\n",
      "Epoch 13/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.2000\n",
      "Epoch 00013: val_loss did not improve from 4.36364\n",
      "237/237 [==============================] - 90s 379ms/step - loss: 3.2000 - val_loss: 4.3665\n",
      "Epoch 14/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.0780\n",
      "Epoch 00014: val_loss improved from 4.36364 to 4.35320, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 91s 386ms/step - loss: 3.0780 - val_loss: 4.3532\n",
      "Epoch 15/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.9661\n",
      "Epoch 00015: val_loss improved from 4.35320 to 4.34142, saving model to /home/ssac7/aiffel/news_summarization/models/e11_abstractive2\n",
      "237/237 [==============================] - 95s 402ms/step - loss: 2.9661 - val_loss: 4.3414\n",
      "Epoch 16/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.8625\n",
      "Epoch 00016: val_loss did not improve from 4.34142\n",
      "237/237 [==============================] - 94s 396ms/step - loss: 2.8625 - val_loss: 4.3458\n",
      "Epoch 17/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.7708\n",
      "Epoch 00017: val_loss did not improve from 4.34142\n",
      "237/237 [==============================] - 95s 400ms/step - loss: 2.7708 - val_loss: 4.3482\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 저장경로\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/news_summarization/models/e11_abstractive2'\n",
    "# optimizer도 adam으로 바꿔봄\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2),\n",
    "      ModelCheckpoint(filepath = checkpoint_dir, save_weights_only=True, monitor='val_loss', mode='auto', save_best_only=True, verbose=1)]\n",
    "# 훈련\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ validation loss 감소 그래프 상 큰 차이는 없는 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2cdc06c050>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : wanted minister assets wants brand current kapoor wishes every baby suspended enough passengers co media build territories ocean procession added wants problems mother days current watch commerce whatsapp transported major arm co media humour \n",
      "실제 요약 : head buddha the fir said had attacks london \n",
      "예측 요약 :  air india tweets user on flight morphed pics of wedding\n",
      "\n",
      "\n",
      "원문 : changed nagar kailash cooperation tuesday juventus killed security nuclear trump terror road support health authorities tihar police pm said aamir india match margin requests sequence rahul authorities first case reportedly authorities tharoor unlike changed \n",
      "실제 요약 : representing punjabi pakistan ex by this electric in \n",
      "예측 요약 :  trump asks pm trump to represent him for london attack\n",
      "\n",
      "\n",
      "원문 : mumbai year two coalition devote official announced reportedly series first thursday volcano year two aid salman congress pumps metoo alleged official official spark revolution electronics three elected congress reportedly education official governor full despite aid salman days \n",
      "실제 요약 : year was mumbai boy minister her st colleague \n",
      "예측 요약 :  mumbai to get first first ever to visit mumbai house\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(70, 73):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 패딩, recurrent_dropout, embedding_dim, hidden_size 모두 변화를 줘 봤지만 요약이 잘 된것 같지는 않다. 뭐가 문제인지 잘 모르겠다. 잘 된 케이스를 보고 뭘 다르게 했는지 아이디어를 얻을 수 있으면 좋겠다.\n",
    "+ validation loss 가 train loss에 비해 일찍 정체가 와서 오버피팅 문제가 있나 싶어 recurrent_dropout 인자를 설정해 봤지만 크게 도움이 된 것 같지는 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 추출적 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Italian third division football side Lucchese's head coach Giancarlo Favarin has been banned for five months for headbutting Alessandria's assistant coach Gaetano Mancino during a brawl following the teams' 2-2 draw on Sunday. Mancino was caught off-balance and knocked to the ground after the headbutt. Earlier in the match, Favarin had told his own player to break an opponent's legs.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.iloc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Italian third division football side Lucchese's head coach Giancarlo Favarin has been banned for five months for headbutting Alessandria's assistant coach Gaetano Mancino during a brawl following the teams' 2-2 draw on Sunday.\n",
      "actual headline:\n",
      "Italian coach knocks rival down with headbutt, banned for 5 months\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(data.text.iloc[30], ratio=0.5))\n",
    "print('actual headline:')\n",
    "print(data.headlines.iloc[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[\"Italian third division football side Lucchese's head coach Giancarlo Favarin has been banned for five months for headbutting Alessandria's assistant coach Gaetano Mancino during a brawl following the teams' 2-2 draw on Sunday.\"]\n",
      "actual headline:\n",
      "Italian coach knocks rival down with headbutt, banned for 5 months\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(data.text.iloc[30], ratio=0.5, split=True))\n",
    "print('actual headline:')\n",
    "print(data.headlines.iloc[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Italian third division football side Lucchese's head coach Giancarlo Favarin has been banned for five months for headbutting Alessandria's assistant coach Gaetano Mancino during a brawl following the teams' 2-2 draw on Sunday.\n",
      "actual headline:\n",
      "Italian coach knocks rival down with headbutt, banned for 5 months\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(data.text.iloc[30], words=19))\n",
    "print('actual headline:')\n",
    "print(data.headlines.iloc[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 추출적 요약은 ratio 나 words 를 작은 수치로 지정하면 문자열을 반환하는데 실패한다.\n",
    "+ 추출적 요약이 문법적인 완성도나 핵심 단어는 잘 포함하는 것 같다. 추상적 요약은 핵심 단어가 들어가기는 하나 문법적인 완성도가 떨어지는 경우가 많이 있고, 오히려 반대의 뜻으로 요약하는 경우도 있었다.\n",
    "+ 다만 추상적 요약은 원하는 짧은 길이로 요약하도록 학습시킬 수 있는 반면, 추출적 요약은 원 글이 짧을 경우 상당한 비율로의 요약만 가능하며 아주 짧은 토막 요약은 불가능한 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
